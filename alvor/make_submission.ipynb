{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf34ef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import os, sys, pickle, glob, gc\n",
    "from collections import Counter\n",
    "import itertools\n",
    "pd.set_option('display.max_columns', None)\n",
    "from otto_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1aa6bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(filter(os.path.isfile, glob.glob(\"models/*\")))\n",
    "files.sort(key=lambda x: os.path.getmtime(x))\n",
    "models_all = [x for x in files if (x.startswith(\"models/lgb_\") and not (x.startswith(\"models/lgb_oof\")))][-9:]\n",
    "\n",
    "models = dict()\n",
    "\n",
    "models['clicks'] = [x for x in models_all if x.startswith(\"models/lgb_clicks\")]\n",
    "models['carts'] = [x for x in models_all if x.startswith(\"models/lgb_carts\")]\n",
    "models['orders'] = [x for x in models_all if x.startswith(\"models/lgb_orders\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f633d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/lgb_clicks_2000_tr_16_lv_gbdt_fold_0_0.9365_0.548282.pkl',\n",
       " 'models/lgb_clicks_2000_tr_16_lv_gbdt_fold_1_0.9371_0.534971.pkl',\n",
       " 'models/lgb_clicks_2000_tr_16_lv_gbdt_fold_2_0.9356_0.537237.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['clicks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19c17a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/lgb_carts_2000_tr_36_lv_dart_fold_0_0.9267_0.423757.pkl',\n",
       " 'models/lgb_carts_2000_tr_36_lv_dart_fold_1_0.9289_0.437912.pkl',\n",
       " 'models/lgb_carts_2000_tr_36_lv_dart_fold_2_0.9261_0.407463.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['carts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bbb1a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/lgb_orders_2000_tr_16_lv_gbdt_fold_0_0.9716_0.685294.pkl',\n",
       " 'models/lgb_orders_2000_tr_16_lv_gbdt_fold_1_0.9651_0.634890.pkl',\n",
       " 'models/lgb_orders_2000_tr_16_lv_gbdt_fold_2_0.9652_0.606256.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['orders']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f61343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict = {\n",
    "    'orders': [\n",
    "        'a2s_actions_rel', 'a2s_best_action_type', 'a2s_actions_num', 'a2s_last_action_index', 'ts_diff',\n",
    "        'a2s_carts_rel', 'a2s_last_click_index', 'a2s_last_cart_index', 'a2s_carts_num', 'wgt_v51ha_sum',\n",
    "        'OR_estimation_frCA_trn', 'aid_CL2OR_trn', 'ts_diff_clicks', 'wgt_v21m_sum', 'session_actions',\n",
    "        'session_carts', 'wgt_rel_v51ha_mean', 'wgt_v21k_sum', 'v51ha_indmin', 'wgt_rel_v51ha_sum',\n",
    "        'wgt_rel_v21m_sum', 'wgt_v31m_sum', 'session_carts_avg_real', 'ts_diff_carts', 'ts_diff_orders_rel',\n",
    "        'a2s_clicks_rel', 'OR_estimation_frCL_trn', 'session_clicks', 'carts_rating_full', 'ts_diff_clicks_rel',\n",
    "        'session_carts_avg_hour', 'ts_diff_carts_rel', 'ts_diff_rel', 'wgt_rel_v31m_sum', 'wgt_rel_v21m_mean',\n",
    "        'session_full_length', 'aid_CL2CA_tst', 'aid_CA2OR_trn', 'v21m_indmin', 'a2s_orders_rel',\n",
    "        'session_items_carted', 'aid_CA_rank_int_tst_vs_trn', 'session_avg_real_length', 'ts_diff_orders',\n",
    "        'carts_rating_train', 'v21k_num', 'wgt_v51ha_mean', 'orders_rating_full', 'aid_multi_orders_percent_train',\n",
    "        'aid_multi_clicks_percent_full'\n",
    "    ],\n",
    "    'carts': [\n",
    "        'a2s_last_action_index', 'ts_diff', 'a2s_actions_rel', 'ts_diff_rel', 'wgt_v51ha_sum', 'wgt_v21m_sum',\n",
    "        'wgt_rel_v21m_sum', 'wgt_rel_v51ha_sum', 'session_clicks', 'wgt_v31m_sum', 'a2s_clicks_rel',\n",
    "        'wgt_rel_v51ha_mean', 'wgt_v21k_sum', 'v51ha_indmin', 'session_items_clicked', 'wgt_rel_v31m_sum',\n",
    "        'session_items', 'v21m_indmin', 'wgt_rel_v21k_sum', 'wgt_v11m_sum', 'a2s_last_click_index', \n",
    "        'wgt_rel_v21m_mean', 'aid_CL2CA_tst', 'ts_diff_carts_rel', 'CA_estimation_frCL_trn', 'aid_CL2CA_trn',\n",
    "        'ts_diff_clicks_rel', 'clicks_rating_train', 'ts_diff_orders_rel', 'aid_CL_vs_mean_trn', 'ts_diff_clicks',\n",
    "        'aid_CL_rank_int_tst_vs_trn', 'session_full_length', 'aid_multi_clicks_percent_full', 'wgt_v51ha_mean',\n",
    "        'session_avg_real_items_num', 'a2s_actions_num', 'aid_CL_rank_int_trn', 'v31m_num', 'v31m_indmin',\n",
    "        'a2s_clicks_num', 'CA_estimation_frCL_tst', 'wgt_rel_v21k_mean', 'aid_CL_vs_mean_tst_vs_trn',\n",
    "        'aid_CL_rank_pct_tst_vs_trn', 'aid_CA_rank_int_tst_vs_trn', 'aid_CA_vs_mean_tst', 'clicks_rating_full',\n",
    "        'session_click_diff_mean', 'aid_CA_vs_mean_tst_vs_trn'\n",
    "    ],\n",
    "    'clicks': [\n",
    "        'a2s_last_action_index', 'a2s_actions_rel', 'ts_diff', 'session_actions', 'wgt_rel_v31m_mean', \n",
    "        'wgt_v31m_sum', 'wgt_rel_v11m_mean', 'v31m_indmin', 'wgt_rel_v31m_sum', 'wgt_v11m_sum', 'v11m_indmin',\n",
    "        'session_items', 'session_clicks', 'session_full_length', 'wgt_v11m_mean', 'aid_CL_rank_int_tst_vs_trn',\n",
    "        'wgt_v31m_mean', 'ts_diff_carts_rel', 'ts_diff_rel', 'aid_CL_vs_mean_tst_vs_trn', 'a2s_actions_num',\n",
    "        'session_avg_real_items_num', 'v31m_num', 'ts_diff_orders_rel', 'ts_diff_clicks_rel', \n",
    "        'session_items_clicked', 'aid_multi_clicks_percent_full', 'aid_CL_rank_pct_tst_vs_trn', 'wgt_v51ha_sum',\n",
    "        'aid_CL_vs_mean_trn', 'v21k_num', 'wgt_rel_v21k_sum', 'wgt_v21m_sum', 'carts_rating_train', 'wgt_v21m_mean', \n",
    "        'wgt_rel_v11m_sum', 'aid_CA_vs_mean_trn', 'ts_diff_clicks', 'wgt_v21k_sum', 'v11m_num', \n",
    "        'a2s_last_click_index', 'clicks_rating_full', 'wgt_rel_v21k_mean', 'clicks_rating_train', \n",
    "        'aid_clicks_favourite_dow_diff_test', 'a2s_carts_rel', 'wgt_rel_v21m_mean', 'wgt_v51ha_mean', \n",
    "        'wgt_rel_v51ha_mean', 'CA_estimation_frCL_trn'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff330e52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict clicks:\n",
      "\n",
      "\n",
      "batch 0:\n",
      "______________________________\n",
      "Predict clicks with model 0 ...\n",
      "done\n",
      "Predict clicks with model 1 ...\n",
      "done\n",
      "Predict clicks with model 2 ...\n",
      "done\n",
      "Make clicks submission...\n",
      "\n",
      "batch 1:\n",
      "______________________________\n",
      "Predict clicks with model 0 ...\n",
      "done\n",
      "Predict clicks with model 1 ...\n",
      "done\n",
      "Predict clicks with model 2 ...\n",
      "done\n",
      "Make clicks submission...\n",
      "\n",
      "batch 2:\n",
      "______________________________\n",
      "Predict clicks with model 0 ...\n",
      "done\n",
      "Predict clicks with model 1 ...\n",
      "done\n",
      "Predict clicks with model 2 ...\n",
      "done\n",
      "Make clicks submission...\n",
      "\n",
      "batch 3:\n",
      "______________________________\n",
      "Predict clicks with model 0 ...\n",
      "done\n",
      "Predict clicks with model 1 ...\n",
      "done\n",
      "Predict clicks with model 2 ...\n",
      "done\n",
      "Make clicks submission...\n"
     ]
    }
   ],
   "source": [
    "VER = '1'\n",
    "\n",
    "target = 'clicks'\n",
    "\n",
    "pub_sh1_1 = ['emb_diff_sh1_1_pub','emb_angle_sh1_1_pub']\n",
    "pub_sh2_1 = ['emb_diff_sh2_1_pub','emb_angle_sh2_1_pub']\n",
    "w2v = ['emb_diff_w2v','emb_angle_w2v']\n",
    "emb_feats = pub_sh1_1+pub_sh2_1+w2v\n",
    "\n",
    "features = out_dict['clicks'] + [\n",
    "    'matrices_num','matrices_numsum','matrices_wgt_rel_mean'\n",
    "] + emb_feats\n",
    "\n",
    "print(f\"Predict {target}:\\n\")\n",
    "for batch in range(4):\n",
    "    print(f\"\\nbatch {batch}:\")\n",
    "    print(\"_\"*30)\n",
    "    train = pd.read_parquet(f\"feats/feats_1_batch_{batch}.pqt\")\n",
    "    \n",
    "    N = len(models[target])\n",
    "\n",
    "    for i, model_file in enumerate(models[target]):\n",
    "        with open(model_file, 'rb') as file:\n",
    "            model = pickle.load(file)\n",
    "        print(f\"Predict {target} with model {i} ...\")    \n",
    "        pred = model.predict(train[features])\n",
    "        print(\"done\")\n",
    "        if i==0:\n",
    "            preds = (1/N) * pred\n",
    "        else:\n",
    "            preds += (1/N) * pred\n",
    "\n",
    "    save_object(preds, f\"output/pred_{target}_v{VER + 'abcd'[batch]}.pkl\")\n",
    "    gc_clear()\n",
    "\n",
    "    print(f\"Make {target} submission...\")\n",
    "\n",
    "    prepare_submission(\n",
    "        train[['session','aid']].copy(), \n",
    "        preds, \n",
    "        target, \n",
    "        VER + 'abcd'[batch]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e630895",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict carts:\n",
      "\n",
      "\n",
      "batch 0:\n",
      "______________________________\n",
      "Predict carts with model 0 ...\n",
      "done\n",
      "Predict carts with model 1 ...\n",
      "done\n",
      "Predict carts with model 2 ...\n",
      "done\n",
      "Make carts submission...\n",
      "\n",
      "batch 1:\n",
      "______________________________\n",
      "Predict carts with model 0 ...\n",
      "done\n",
      "Predict carts with model 1 ...\n",
      "done\n",
      "Predict carts with model 2 ...\n",
      "done\n",
      "Make carts submission...\n",
      "\n",
      "batch 2:\n",
      "______________________________\n",
      "Predict carts with model 0 ...\n",
      "done\n",
      "Predict carts with model 1 ...\n",
      "done\n",
      "Predict carts with model 2 ...\n",
      "done\n",
      "Make carts submission...\n",
      "\n",
      "batch 3:\n",
      "______________________________\n",
      "Predict carts with model 0 ...\n",
      "done\n",
      "Predict carts with model 1 ...\n",
      "done\n",
      "Predict carts with model 2 ...\n",
      "done\n",
      "Make carts submission...\n",
      "Predict orders:\n",
      "\n",
      "\n",
      "batch 0:\n",
      "______________________________\n",
      "Predict orders with model 0 ...\n",
      "done\n",
      "Predict orders with model 1 ...\n",
      "done\n",
      "Predict orders with model 2 ...\n",
      "done\n",
      "Make orders submission...\n",
      "\n",
      "batch 1:\n",
      "______________________________\n",
      "Predict orders with model 0 ...\n",
      "done\n",
      "Predict orders with model 1 ...\n",
      "done\n",
      "Predict orders with model 2 ...\n",
      "done\n",
      "Make orders submission...\n",
      "\n",
      "batch 2:\n",
      "______________________________\n",
      "Predict orders with model 0 ...\n",
      "done\n",
      "Predict orders with model 1 ...\n",
      "done\n",
      "Predict orders with model 2 ...\n",
      "done\n",
      "Make orders submission...\n",
      "\n",
      "batch 3:\n",
      "______________________________\n",
      "Predict orders with model 0 ...\n",
      "done\n",
      "Predict orders with model 1 ...\n",
      "done\n",
      "Predict orders with model 2 ...\n",
      "done\n",
      "Make orders submission...\n"
     ]
    }
   ],
   "source": [
    "VER = '1'\n",
    "\n",
    "target = 'carts'\n",
    "\n",
    "\n",
    "pub_sh1_1 = ['emb_diff_sh1_1_pub','emb_angle_sh1_1_pub']\n",
    "pub_sh2_1 = ['emb_diff_sh2_1_pub','emb_angle_sh2_1_pub']\n",
    "w2v = ['emb_diff_w2v_100','emb_angle_w2v_100']\n",
    "embs_feats = pub_sh1_1 + pub_sh2_1 + w2v\n",
    "\n",
    "features = out_dict['carts'] + [\n",
    "    'matrices_num','matrices_numsum','matrices_wgt_rel_mean'\n",
    "] + embs_feats\n",
    "\n",
    "print(f\"Predict {target}:\\n\")\n",
    "for batch in range(4):\n",
    "    print(f\"\\nbatch {batch}:\")\n",
    "    print(\"_\"*30)\n",
    "    train = pd.read_parquet(f\"feats/feats_1_batch_{batch}.pqt\")\n",
    "    \n",
    "    N = len(models[target])\n",
    "\n",
    "    for i, model_file in enumerate(models[target]):\n",
    "        with open(model_file, 'rb') as file:\n",
    "            model = pickle.load(file)\n",
    "        print(f\"Predict {target} with model {i} ...\")    \n",
    "        pred = model.predict(train[features])\n",
    "        print(\"done\")\n",
    "        if i==0:\n",
    "            preds = (1/N) * pred\n",
    "        else:\n",
    "            preds += (1/N) * pred\n",
    "\n",
    "    save_object(preds, f\"output/pred_{target}_v{VER + 'abcd'[batch]}.pkl\")\n",
    "    gc_clear()\n",
    "\n",
    "    print(f\"Make {target} submission...\")\n",
    "\n",
    "    prepare_submission(\n",
    "        train[['session','aid']].copy(), \n",
    "        preds, \n",
    "        target, \n",
    "        VER + 'abcd'[batch]\n",
    "    )\n",
    "    \n",
    "######################################################################\n",
    "\n",
    "VER = '1'\n",
    "\n",
    "target = 'orders'\n",
    "\n",
    "features = out_dict['orders'] + [\n",
    "    'carts_pred'\n",
    "] + embs_feats\n",
    "\n",
    "print(f\"Predict {target}:\\n\")\n",
    "for batch in range(4):\n",
    "    print(f\"\\nbatch {batch}:\")\n",
    "    print(\"_\"*30)\n",
    "    train = pd.read_parquet(f\"feats/feats_1_batch_{batch}.pqt\")\n",
    "    with open(f\"output/pred_carts_v{VER + 'abcd'[batch]}.pkl\", 'rb') as file:\n",
    "        carts_pred = pickle.load(file)\n",
    "    train['carts_pred'] = carts_pred\n",
    "    del carts_pred\n",
    "    gc_clear()\n",
    "    \n",
    "    N = len(models[target])\n",
    "\n",
    "    for i, model_file in enumerate(models[target]):\n",
    "        with open(model_file, 'rb') as file:\n",
    "            model = pickle.load(file)\n",
    "        print(f\"Predict {target} with model {i} ...\")    \n",
    "        pred = model.predict(train[features])\n",
    "        print(\"done\")\n",
    "        if i==0:\n",
    "            preds = (1/N) * pred\n",
    "        else:\n",
    "            preds += (1/N) * pred\n",
    "\n",
    "    save_object(preds, f\"output/pred_{target}_v{VER + 'abcd'[batch]}.pkl\")\n",
    "    gc_clear()\n",
    "\n",
    "    print(f\"Make {target} submission...\")\n",
    "\n",
    "    prepare_submission(\n",
    "        train[['session','aid']].copy(), \n",
    "        preds, \n",
    "        target, \n",
    "        VER + 'abcd'[batch]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c01d899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12900000_clicks</td>\n",
       "      <td>1635995 515459 606565 1349330 76103 18262 1961...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12900400_clicks</td>\n",
       "      <td>1199617 349404 1539309 136822 666350 891513 90...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12900800_clicks</td>\n",
       "      <td>322935 1260870 87613 102466 468342 1131560 133...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12901200_clicks</td>\n",
       "      <td>324603 1321398 461211 1685607 977147 36276 128...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12901600_clicks</td>\n",
       "      <td>1033509 995815 111668 1222592 27663 567933 142...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50143</th>\n",
       "      <td>14569603_orders</td>\n",
       "      <td>182696 375761 278972 1380414 1557744 843567 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50144</th>\n",
       "      <td>14570003_orders</td>\n",
       "      <td>27659 1725935 1063957 884771 1655203 1711340 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50145</th>\n",
       "      <td>14570403_orders</td>\n",
       "      <td>866342 217213 1592514 619203 1206098 1084805 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50146</th>\n",
       "      <td>14570803_orders</td>\n",
       "      <td>1387843 210222 282621 1808913 1653338 821957 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50147</th>\n",
       "      <td>14571203_orders</td>\n",
       "      <td>1142507 507546 1377400 200701 197280 889284 16...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50148 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_type                                             labels\n",
       "0      12900000_clicks  1635995 515459 606565 1349330 76103 18262 1961...\n",
       "1      12900400_clicks  1199617 349404 1539309 136822 666350 891513 90...\n",
       "2      12900800_clicks  322935 1260870 87613 102466 468342 1131560 133...\n",
       "3      12901200_clicks  324603 1321398 461211 1685607 977147 36276 128...\n",
       "4      12901600_clicks  1033509 995815 111668 1222592 27663 567933 142...\n",
       "...                ...                                                ...\n",
       "50143  14569603_orders  182696 375761 278972 1380414 1557744 843567 13...\n",
       "50144  14570003_orders  27659 1725935 1063957 884771 1655203 1711340 1...\n",
       "50145  14570403_orders  866342 217213 1592514 619203 1206098 1084805 1...\n",
       "50146  14570803_orders  1387843 210222 282621 1808913 1653338 821957 1...\n",
       "50147  14571203_orders  1142507 507546 1377400 200701 197280 889284 16...\n",
       "\n",
       "[50148 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VER = {'clicks':'1','carts':'1','orders':'1'}\n",
    "\n",
    "sub = pd.concat(\n",
    "    [\n",
    "        pd.read_parquet(f\"output/sub_{target}_lgbm_v{VER[target] + v}.pqt\")\n",
    "        for target in ['clicks','carts','orders']\n",
    "        for v in 'abcd'\n",
    "    ],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "sub.to_csv('output/submission.csv',index=False)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3496dbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = {0:'a',1:'b',2:'c',3:'d'}\n",
    "\n",
    "outs = []\n",
    "\n",
    "for i in range(4):\n",
    "    b = pd.read_parquet(f\"feats/feats_1_batch_{i}.pqt\",columns = ['session','aid'])\n",
    "    with open(f\"output/pred_clicks_v1{dct[i]}.pkl\", 'rb') as file:\n",
    "        b['clicks_pred'] = pickle.load(file)\n",
    "    with open(f\"output/pred_carts_v1{dct[i]}.pkl\", 'rb') as file:\n",
    "        b['carts_pred'] = pickle.load(file)\n",
    "    with open(f\"output/pred_orders_v1{dct[i]}.pkl\", 'rb') as file:\n",
    "        b['orders_pred'] = pickle.load(file)\n",
    "    outs.append(b)\n",
    "\n",
    "out = pd.concat(outs, ignore_index=True)\n",
    "        \n",
    "out.to_parquet(f\"output/alvor_raw_predictions_596.parquet\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c639912",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    [\n",
    "        pd.read_parquet(\"feats/feats_0_batch_0.pqt\", columns = ['session','aid']),\n",
    "        pd.read_parquet(\"feats/feats_0_batch_1.pqt\", columns = ['session','aid']),\n",
    "        pd.read_parquet(\"feats/feats_0_batch_2.pqt\", columns = ['session','aid']),\n",
    "        pd.read_parquet(\"feats/feats_0_batch_3.pqt\", columns = ['session','aid']),\n",
    "    ],\n",
    "    ignore_index=True\n",
    ").to_parquet(\"output/alvor_candidates_big.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a70de24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d36206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_parquet(\"output/alvor_candidates_big.parquet\")\n",
    "with open(\"models/lgb_oof_clicks.pkl\",\"rb\") as f:\n",
    "    b = pickle.load(f)\n",
    "a['clicks_pred'] = b\n",
    "a.to_parquet(\"output/alvor_oof_clicks.parquet\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a7038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.concat(\n",
    "    [\n",
    "        pd.read_parquet(\"feats/feats_0_batch_0_small.pqt\",columns = ['session','aid']),\n",
    "        pd.read_parquet(\"feats/feats_0_batch_1_small.pqt\",columns = ['session','aid']),\n",
    "        pd.read_parquet(\"feats/feats_0_batch_2_small.pqt\",columns = ['session','aid']),\n",
    "        pd.read_parquet(\"feats/feats_0_batch_3_small.pqt\",columns = ['session','aid']),\n",
    "    ],\n",
    "    ignore_index=True\n",
    ")\n",
    "with open(\"models/lgb_oof_carts.pkl\",\"rb\") as f:\n",
    "    b = pickle.load(f)\n",
    "with open(\"models/lgb_oof_orders.pkl\",\"rb\") as f:\n",
    "    c = pickle.load(f)\n",
    "a['orders_pred'] = c\n",
    "a['carts_pred'] = b\n",
    "a.to_parquet(\"output/alvor_oof_carts_orders.parquet\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
