{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7b19c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import os, sys, pickle, glob, gc\n",
    "from collections import Counter\n",
    "import itertools\n",
    "pd.set_option('display.max_columns', None)\n",
    "from otto_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f279137b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(filter(os.path.isfile, glob.glob(\"models_new/*\")))\n",
    "files.sort(key=lambda x: os.path.getmtime(x))\n",
    "models_all = [x for x in files if (x.startswith(\"models_new/lgb_\") and not (x.startswith(\"models_new/lgb_oof\")))][-9:]\n",
    "\n",
    "models = dict()\n",
    "\n",
    "models['clicks'] = [x for x in models_all if x.startswith(\"models_new/lgb_clicks\")]\n",
    "models['carts'] = [x for x in models_all if x.startswith(\"models_new/lgb_carts\")]\n",
    "models['orders'] = [x for x in models_all if x.startswith(\"models_new/lgb_orders\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "355d5bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models_new/lgb_clicks_2000_tr_16_lv_gbdt_fold_0_0.9347_0.545548.pkl',\n",
       " 'models_new/lgb_clicks_2000_tr_16_lv_gbdt_fold_1_0.9347_0.530706.pkl',\n",
       " 'models_new/lgb_clicks_2000_tr_16_lv_gbdt_fold_2_0.9361_0.537066.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['clicks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3894eb80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models_new/lgb_carts_2000_tr_36_lv_dart_fold_0_0.9274_0.423204.pkl',\n",
       " 'models_new/lgb_carts_2000_tr_36_lv_dart_fold_1_0.9265_0.433516.pkl',\n",
       " 'models_new/lgb_carts_2000_tr_36_lv_dart_fold_2_0.9271_0.404942.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['carts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d85d6b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models_new/lgb_orders_2000_tr_16_lv_gbdt_fold_0_0.9716_0.682353.pkl',\n",
       " 'models_new/lgb_orders_2000_tr_16_lv_gbdt_fold_1_0.9650_0.637750.pkl',\n",
       " 'models_new/lgb_orders_2000_tr_16_lv_gbdt_fold_2_0.9629_0.607176.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['orders']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef472687",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict = {\n",
    "    'orders': [\n",
    "        'a2s_actions_rel', 'a2s_best_action_type', 'a2s_actions_num', 'a2s_last_action_index', 'ts_diff',\n",
    "        'a2s_carts_rel', 'a2s_last_click_index', 'a2s_last_cart_index', 'a2s_carts_num', 'wgt_v51ha_sum',\n",
    "        'OR_estimation_frCA_trn', 'aid_CL2OR_trn', 'ts_diff_clicks', 'wgt_v21m_sum', 'session_actions',\n",
    "        'session_carts', 'wgt_rel_v51ha_mean', 'wgt_v21k_sum', 'v51ha_indmin', 'wgt_rel_v51ha_sum',\n",
    "        'wgt_rel_v21m_sum', 'wgt_v31m_sum', 'session_carts_avg_real', 'ts_diff_carts', 'ts_diff_orders_rel',\n",
    "        'a2s_clicks_rel', 'OR_estimation_frCL_trn', 'session_clicks', 'carts_rating_full', 'ts_diff_clicks_rel',\n",
    "        'session_carts_avg_hour', 'ts_diff_carts_rel', 'ts_diff_rel', 'wgt_rel_v31m_sum', 'wgt_rel_v21m_mean',\n",
    "        'session_full_length', 'aid_CL2CA_tst', 'aid_CA2OR_trn', 'v21m_indmin', 'a2s_orders_rel',\n",
    "        'session_items_carted', 'aid_CA_rank_int_tst_vs_trn', 'session_avg_real_length', 'ts_diff_orders',\n",
    "        'carts_rating_train', 'v21k_num', 'wgt_v51ha_mean', 'orders_rating_full', 'aid_multi_orders_percent_train',\n",
    "        'aid_multi_clicks_percent_full'\n",
    "    ],\n",
    "    'carts': [\n",
    "        'a2s_last_action_index', 'ts_diff', 'a2s_actions_rel', 'ts_diff_rel', 'wgt_v51ha_sum', 'wgt_v21m_sum',\n",
    "        'wgt_rel_v21m_sum', 'wgt_rel_v51ha_sum', 'session_clicks', 'wgt_v31m_sum', 'a2s_clicks_rel',\n",
    "        'wgt_rel_v51ha_mean', 'wgt_v21k_sum', 'v51ha_indmin', 'session_items_clicked', 'wgt_rel_v31m_sum',\n",
    "        'session_items', 'v21m_indmin', 'wgt_rel_v21k_sum', 'wgt_v11m_sum', 'a2s_last_click_index', \n",
    "        'wgt_rel_v21m_mean', 'aid_CL2CA_tst', 'ts_diff_carts_rel', 'CA_estimation_frCL_trn', 'aid_CL2CA_trn',\n",
    "        'ts_diff_clicks_rel', 'clicks_rating_train', 'ts_diff_orders_rel', 'aid_CL_vs_mean_trn', 'ts_diff_clicks',\n",
    "        'aid_CL_rank_int_tst_vs_trn', 'session_full_length', 'aid_multi_clicks_percent_full', 'wgt_v51ha_mean',\n",
    "        'session_avg_real_items_num', 'a2s_actions_num', 'aid_CL_rank_int_trn', 'v31m_num', 'v31m_indmin',\n",
    "        'a2s_clicks_num', 'CA_estimation_frCL_tst', 'wgt_rel_v21k_mean', 'aid_CL_vs_mean_tst_vs_trn',\n",
    "        'aid_CL_rank_pct_tst_vs_trn', 'aid_CA_rank_int_tst_vs_trn', 'aid_CA_vs_mean_tst', 'clicks_rating_full',\n",
    "        'session_click_diff_mean', 'aid_CA_vs_mean_tst_vs_trn'\n",
    "    ],\n",
    "    'clicks': [\n",
    "        'a2s_last_action_index', 'a2s_actions_rel', 'ts_diff', 'session_actions', 'wgt_rel_v31m_mean', \n",
    "        'wgt_v31m_sum', 'wgt_rel_v11m_mean', 'v31m_indmin', 'wgt_rel_v31m_sum', 'wgt_v11m_sum', 'v11m_indmin',\n",
    "        'session_items', 'session_clicks', 'session_full_length', 'wgt_v11m_mean', 'aid_CL_rank_int_tst_vs_trn',\n",
    "        'wgt_v31m_mean', 'ts_diff_carts_rel', 'ts_diff_rel', 'aid_CL_vs_mean_tst_vs_trn', 'a2s_actions_num',\n",
    "        'session_avg_real_items_num', 'v31m_num', 'ts_diff_orders_rel', 'ts_diff_clicks_rel', \n",
    "        'session_items_clicked', 'aid_multi_clicks_percent_full', 'aid_CL_rank_pct_tst_vs_trn', 'wgt_v51ha_sum',\n",
    "        'aid_CL_vs_mean_trn', 'v21k_num', 'wgt_rel_v21k_sum', 'wgt_v21m_sum', 'carts_rating_train', 'wgt_v21m_mean', \n",
    "        'wgt_rel_v11m_sum', 'aid_CA_vs_mean_trn', 'ts_diff_clicks', 'wgt_v21k_sum', 'v11m_num', \n",
    "        'a2s_last_click_index', 'clicks_rating_full', 'wgt_rel_v21k_mean', 'clicks_rating_train', \n",
    "        'aid_clicks_favourite_dow_diff_test', 'a2s_carts_rel', 'wgt_rel_v21m_mean', 'wgt_v51ha_mean', \n",
    "        'wgt_rel_v51ha_mean', 'CA_estimation_frCL_trn'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68fb5b4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_feats = list(set(out_dict['clicks']) | set(out_dict['carts']) | set(out_dict['orders']))\n",
    "len(full_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e702a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_feats = [\n",
    "    'bigram_normed_clicks_sum', 'bigram_normed_clicks_mean', 'bigram_normed_clicks_max', 'bigram_normed_clicks_min', \n",
    "    'bigram_normed_clicks_last', 'bigram_normed_carts_sum', 'bigram_normed_carts_mean', 'bigram_normed_carts_max', \n",
    "    'bigram_normed_carts_min', 'bigram_normed_carts_last', 'bigram_more_clicks_sum', 'bigram_more_clicks_mean', \n",
    "    'bigram_more_clicks_max', 'bigram_more_clicks_min', 'bigram_more_clicks_last', 'bigram_more_carts_sum', \n",
    "    'bigram_more_carts_mean', 'bigram_more_carts_max', 'bigram_more_carts_min', 'bigram_more_carts_last' \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89fa6044",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_sh1_1 = ['emb_diff_sh1_1_pub','emb_angle_sh1_1_pub']\n",
    "pub_sh2_1 = ['emb_diff_sh2_1_pub','emb_angle_sh2_1_pub']\n",
    "w2v = ['emb_diff_w2v_100','emb_angle_w2v_100']\n",
    "bpr = ['bpr']\n",
    "\n",
    "embs_feats = pub_sh1_1 + pub_sh2_1 + w2v + bpr + bigram_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91ad8d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "needcols = ['session','aid'] + full_feats + [\n",
    "    'matrices_num','matrices_numsum','matrices_wgt_rel_mean'\n",
    "] + pub_sh1_1 + pub_sh2_1 + w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4a2b9a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict clicks:\n",
      "\n",
      "\n",
      "batch 0:\n",
      "______________________________\n",
      "Predict clicks with model 0 ...\n",
      "done\n",
      "Predict clicks with model 1 ...\n",
      "done\n",
      "Predict clicks with model 2 ...\n",
      "done\n",
      "Make clicks submission...\n",
      "\n",
      "batch 1:\n",
      "______________________________\n",
      "Predict clicks with model 0 ...\n",
      "done\n",
      "Predict clicks with model 1 ...\n",
      "done\n",
      "Predict clicks with model 2 ...\n",
      "done\n",
      "Make clicks submission...\n",
      "\n",
      "batch 2:\n",
      "______________________________\n",
      "Predict clicks with model 0 ...\n",
      "done\n",
      "Predict clicks with model 1 ...\n",
      "done\n",
      "Predict clicks with model 2 ...\n",
      "done\n",
      "Make clicks submission...\n",
      "\n",
      "batch 3:\n",
      "______________________________\n",
      "Predict clicks with model 0 ...\n",
      "done\n",
      "Predict clicks with model 1 ...\n",
      "done\n",
      "Predict clicks with model 2 ...\n",
      "done\n",
      "Make clicks submission...\n"
     ]
    }
   ],
   "source": [
    "VER = '2'\n",
    "\n",
    "target = 'clicks'\n",
    "\n",
    "features = out_dict['clicks'] + [\n",
    "    'matrices_num','matrices_numsum','matrices_wgt_rel_mean'\n",
    "] + embs_feats\n",
    "\n",
    "print(f\"Predict {target}:\\n\")\n",
    "for batch in range(4):\n",
    "    print(f\"\\nbatch {batch}:\")\n",
    "    print(\"_\"*30)\n",
    "    \n",
    "    train = pd.read_parquet(f\"feats/feats_1_batch_{batch}.pqt\",columns = needcols)\n",
    "    \n",
    "    train = pd.concat(\n",
    "        [\n",
    "            train,\n",
    "            pd.read_parquet(f\"matrices/bigram_test_sirius_batch_{batch}.parquet\", columns = bigram_feats)\n",
    "        ],\n",
    "        axis=1\n",
    "    )\n",
    "    train['bpr'] = pd.read_parquet(f\"matrices/bpr_test_batch_{batch}.parquet\")['bpr']\n",
    "    \n",
    "    N = len(models[target])\n",
    "\n",
    "    for i, model_file in enumerate(models[target]):\n",
    "        with open(model_file, 'rb') as file:\n",
    "            model = pickle.load(file)\n",
    "        print(f\"Predict {target} with model {i} ...\")    \n",
    "        pred = model.predict(train[features])\n",
    "        print(\"done\")\n",
    "        if i==0:\n",
    "            preds = (1/N) * pred\n",
    "        else:\n",
    "            preds += (1/N) * pred\n",
    "\n",
    "    save_object(preds, f\"output/pred_{target}_v{VER + 'abcd'[batch]}.pkl\")\n",
    "    gc_clear()\n",
    "\n",
    "    print(f\"Make {target} submission...\")\n",
    "\n",
    "    prepare_submission(\n",
    "        train[['session','aid']].copy(), \n",
    "        preds, \n",
    "        target, \n",
    "        VER + 'abcd'[batch]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "337ec97e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict carts:\n",
      "\n",
      "\n",
      "batch 0:\n",
      "______________________________\n",
      "Predict carts with model 0 ...\n",
      "done\n",
      "Predict carts with model 1 ...\n",
      "done\n",
      "Predict carts with model 2 ...\n",
      "done\n",
      "Make carts submission...\n",
      "\n",
      "batch 1:\n",
      "______________________________\n",
      "Predict carts with model 0 ...\n",
      "done\n",
      "Predict carts with model 1 ...\n",
      "done\n",
      "Predict carts with model 2 ...\n",
      "done\n",
      "Make carts submission...\n",
      "\n",
      "batch 2:\n",
      "______________________________\n",
      "Predict carts with model 0 ...\n",
      "done\n",
      "Predict carts with model 1 ...\n",
      "done\n",
      "Predict carts with model 2 ...\n",
      "done\n",
      "Make carts submission...\n",
      "\n",
      "batch 3:\n",
      "______________________________\n",
      "Predict carts with model 0 ...\n",
      "done\n",
      "Predict carts with model 1 ...\n",
      "done\n",
      "Predict carts with model 2 ...\n",
      "done\n",
      "Make carts submission...\n",
      "Predict orders:\n",
      "\n",
      "\n",
      "batch 0:\n",
      "______________________________\n",
      "Predict orders with model 0 ...\n",
      "done\n",
      "Predict orders with model 1 ...\n",
      "done\n",
      "Predict orders with model 2 ...\n",
      "done\n",
      "Make orders submission...\n",
      "\n",
      "batch 1:\n",
      "______________________________\n",
      "Predict orders with model 0 ...\n",
      "done\n",
      "Predict orders with model 1 ...\n",
      "done\n",
      "Predict orders with model 2 ...\n",
      "done\n",
      "Make orders submission...\n",
      "\n",
      "batch 2:\n",
      "______________________________\n",
      "Predict orders with model 0 ...\n",
      "done\n",
      "Predict orders with model 1 ...\n",
      "done\n",
      "Predict orders with model 2 ...\n",
      "done\n",
      "Make orders submission...\n",
      "\n",
      "batch 3:\n",
      "______________________________\n",
      "Predict orders with model 0 ...\n",
      "done\n",
      "Predict orders with model 1 ...\n",
      "done\n",
      "Predict orders with model 2 ...\n",
      "done\n",
      "Make orders submission...\n"
     ]
    }
   ],
   "source": [
    "VER = '2'\n",
    "\n",
    "target = 'carts'\n",
    "\n",
    "features = out_dict['carts'] + [\n",
    "    'matrices_num','matrices_numsum','matrices_wgt_rel_mean'\n",
    "] + embs_feats\n",
    "\n",
    "print(f\"Predict {target}:\\n\")\n",
    "for batch in range(4):\n",
    "    print(f\"\\nbatch {batch}:\")\n",
    "    print(\"_\"*30)\n",
    "    train = pd.read_parquet(f\"feats/feats_1_batch_{batch}.pqt\")\n",
    "    \n",
    "    train = pd.concat(\n",
    "        [\n",
    "            train,\n",
    "            pd.read_parquet(f\"matrices/bigram_test_sirius_batch_{batch}.parquet\", columns = bigram_feats)\n",
    "        ],\n",
    "        axis=1\n",
    "    )\n",
    "    train['bpr'] = pd.read_parquet(f\"matrices/bpr_test_batch_{batch}.parquet\")['bpr']\n",
    "    \n",
    "    N = len(models[target])\n",
    "\n",
    "    for i, model_file in enumerate(models[target]):\n",
    "        with open(model_file, 'rb') as file:\n",
    "            model = pickle.load(file)\n",
    "        print(f\"Predict {target} with model {i} ...\")    \n",
    "        pred = model.predict(train[features])\n",
    "        print(\"done\")\n",
    "        if i==0:\n",
    "            preds = (1/N) * pred\n",
    "        else:\n",
    "            preds += (1/N) * pred\n",
    "\n",
    "    save_object(preds, f\"output/pred_{target}_v{VER + 'abcd'[batch]}.pkl\")\n",
    "    gc_clear()\n",
    "\n",
    "    print(f\"Make {target} submission...\")\n",
    "\n",
    "    prepare_submission(\n",
    "        train[['session','aid']].copy(), \n",
    "        preds, \n",
    "        target, \n",
    "        VER + 'abcd'[batch]\n",
    "    )\n",
    "    \n",
    "######################################################################\n",
    "\n",
    "VER = '2'\n",
    "\n",
    "target = 'orders'\n",
    "\n",
    "features = out_dict['orders'] + [\n",
    "    'carts_pred'\n",
    "] + embs_feats\n",
    "\n",
    "print(f\"Predict {target}:\\n\")\n",
    "for batch in range(4):\n",
    "    print(f\"\\nbatch {batch}:\")\n",
    "    print(\"_\"*30)\n",
    "    train = pd.read_parquet(f\"feats/feats_1_batch_{batch}.pqt\")\n",
    "    with open(f\"output/pred_carts_v{VER + 'abcd'[batch]}.pkl\", 'rb') as file:\n",
    "        carts_pred = pickle.load(file)\n",
    "    train['carts_pred'] = carts_pred\n",
    "    del carts_pred\n",
    "    gc_clear()\n",
    "    \n",
    "    train = pd.concat(\n",
    "        [\n",
    "            train,\n",
    "            pd.read_parquet(f\"matrices/bigram_test_sirius_batch_{batch}.parquet\", columns = bigram_feats)\n",
    "        ],\n",
    "        axis=1\n",
    "    )\n",
    "    train['bpr'] = pd.read_parquet(f\"matrices/bpr_test_batch_{batch}.parquet\")['bpr']\n",
    "    \n",
    "    N = len(models[target])\n",
    "\n",
    "    for i, model_file in enumerate(models[target]):\n",
    "        with open(model_file, 'rb') as file:\n",
    "            model = pickle.load(file)\n",
    "        print(f\"Predict {target} with model {i} ...\")    \n",
    "        pred = model.predict(train[features])\n",
    "        print(\"done\")\n",
    "        if i==0:\n",
    "            preds = (1/N) * pred\n",
    "        else:\n",
    "            preds += (1/N) * pred\n",
    "\n",
    "    save_object(preds, f\"output/pred_{target}_v{VER + 'abcd'[batch]}.pkl\")\n",
    "    gc_clear()\n",
    "\n",
    "    print(f\"Make {target} submission...\")\n",
    "\n",
    "    prepare_submission(\n",
    "        train[['session','aid']].copy(), \n",
    "        preds, \n",
    "        target, \n",
    "        VER + 'abcd'[batch]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b4a7d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12900000_clicks</td>\n",
       "      <td>1635995 515459 606565 18262 1349330 196149 761...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12900400_clicks</td>\n",
       "      <td>1199617 1539309 349404 891513 666350 136822 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12900800_clicks</td>\n",
       "      <td>322935 87613 1260870 102466 1131560 728827 175...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12901200_clicks</td>\n",
       "      <td>324603 1321398 977147 1685607 461211 36276 996...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12901600_clicks</td>\n",
       "      <td>1033509 111668 27663 995815 1710980 1030029 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50143</th>\n",
       "      <td>14569603_orders</td>\n",
       "      <td>182696 375761 1380414 1557744 843567 278972 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50144</th>\n",
       "      <td>14570003_orders</td>\n",
       "      <td>27659 1063957 1725935 766922 884771 1104060 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50145</th>\n",
       "      <td>14570403_orders</td>\n",
       "      <td>866342 1592514 217213 1206098 619203 1084805 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50146</th>\n",
       "      <td>14570803_orders</td>\n",
       "      <td>1387843 210222 387793 1808913 282621 1653338 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50147</th>\n",
       "      <td>14571203_orders</td>\n",
       "      <td>1142507 1377400 507546 200701 889284 1650164 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50148 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_type                                             labels\n",
       "0      12900000_clicks  1635995 515459 606565 18262 1349330 196149 761...\n",
       "1      12900400_clicks  1199617 1539309 349404 891513 666350 136822 15...\n",
       "2      12900800_clicks  322935 87613 1260870 102466 1131560 728827 175...\n",
       "3      12901200_clicks  324603 1321398 977147 1685607 461211 36276 996...\n",
       "4      12901600_clicks  1033509 111668 27663 995815 1710980 1030029 12...\n",
       "...                ...                                                ...\n",
       "50143  14569603_orders  182696 375761 1380414 1557744 843567 278972 13...\n",
       "50144  14570003_orders  27659 1063957 1725935 766922 884771 1104060 17...\n",
       "50145  14570403_orders  866342 1592514 217213 1206098 619203 1084805 1...\n",
       "50146  14570803_orders  1387843 210222 387793 1808913 282621 1653338 8...\n",
       "50147  14571203_orders  1142507 1377400 507546 200701 889284 1650164 1...\n",
       "\n",
       "[50148 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VER = {'clicks':'2','carts':'2','orders':'2'}\n",
    "\n",
    "sub = pd.concat(\n",
    "    [\n",
    "        pd.read_parquet(f\"output/sub_{target}_lgbm_v{VER[target] + v}.pqt\")\n",
    "        for target in ['clicks','carts','orders']\n",
    "        for v in 'abcd'\n",
    "    ],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "sub.to_csv('output/submission2.csv',index=False)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c2f5803",
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = {0:'a',1:'b',2:'c',3:'d'}\n",
    "\n",
    "outs = []\n",
    "\n",
    "for i in range(4):\n",
    "    b = pd.read_parquet(f\"feats/feats_1_batch_{i}.pqt\",columns = ['session','aid'])\n",
    "    with open(f\"output/pred_clicks_v2{dct[i]}.pkl\", 'rb') as file:\n",
    "        b['clicks_pred'] = pickle.load(file)\n",
    "    with open(f\"output/pred_carts_v2{dct[i]}.pkl\", 'rb') as file:\n",
    "        b['carts_pred'] = pickle.load(file)\n",
    "    with open(f\"output/pred_orders_v2{dct[i]}.pkl\", 'rb') as file:\n",
    "        b['orders_pred'] = pickle.load(file)\n",
    "    outs.append(b)\n",
    "\n",
    "out = pd.concat(outs, ignore_index=True)\n",
    "        \n",
    "out.to_parquet(f\"output/alvor_raw_predictions_599.parquet\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656e219d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463acab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_parquet(\"output/alvor_candidates_big.parquet\")\n",
    "with open(\"models_new/lgb_oof_clicks.pkl\",\"rb\") as f:\n",
    "    b = pickle.load(f)\n",
    "a['clicks_pred'] = b\n",
    "a.to_parquet(\"output/alvor_oof_clicks_v2.parquet\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b8b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.concat(\n",
    "    [\n",
    "        pd.read_parquet(\"feats/feats_0_batch_0_small.pqt\",columns = ['session','aid']),\n",
    "        pd.read_parquet(\"feats/feats_0_batch_1_small.pqt\",columns = ['session','aid']),\n",
    "        pd.read_parquet(\"feats/feats_0_batch_2_small.pqt\",columns = ['session','aid']),\n",
    "        pd.read_parquet(\"feats/feats_0_batch_3_small.pqt\",columns = ['session','aid']),\n",
    "    ],\n",
    "    ignore_index=True\n",
    ")\n",
    "with open(\"models_new/lgb_oof_carts.pkl\",\"rb\") as f:\n",
    "    b = pickle.load(f)\n",
    "with open(\"models_new/lgb_oof_orders.pkl\",\"rb\") as f:\n",
    "    c = pickle.load(f)\n",
    "a['orders_pred'] = c\n",
    "a['carts_pred'] = b\n",
    "a.to_parquet(\"output/alvor_oof_carts_orders_v2.parquet\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
