{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23b682c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import polars as pl\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "train = pd.read_parquet('input/footprint/train.parquet')\n",
    "test = pd.read_parquet('input/footprint/test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f875b2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[(train['aid']!=train['aid'].shift()) | (train['session']!=train['session'].shift())].reset_index()\n",
    "test = test[(test['aid']!=test['aid'].shift()) | (test['session']!=test['session'].shift())].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36bece01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df =  pd.concat([train,test],ignore_index=True).groupby('session')['aid'].apply(list).reset_index(drop=True)\n",
    "\n",
    "sentences = sentences_df.to_list()\n",
    "del sentences_df; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0756b723",
   "metadata": {},
   "outputs": [],
   "source": [
    "class callback(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 1\n",
    "        self.losses = []\n",
    "        self.cumu_loss = 0.0\n",
    "        self.previous_epoch_time = time.time()\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        norms = [np.linalg.norm(v) for v in model.wv.vectors]\n",
    "        now = time.time()\n",
    "        epoch_seconds = now - self.previous_epoch_time\n",
    "        self.previous_epoch_time = now\n",
    "        self.cumu_loss += float(loss)\n",
    "        print(f\"Loss after epoch {self.epoch}: {loss} (cumulative loss so far: {self.cumu_loss}) \"+\\\n",
    "              f\"-> epoch took {round(epoch_seconds, 2)} s - vector norms min/avg/max: \"+\\\n",
    "              f\"{round(float(min(norms)), 2)}, {round(float(sum(norms)/len(norms)), 2)}, {round(float(max(norms)), 2)}\")\n",
    "        self.epoch += 1\n",
    "        self.losses.append(float(loss))\n",
    "        model.running_training_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f6dbd0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 1: 17247084.0 (cumulative loss so far: 17247084.0) -> epoch took 590.66 s - vector norms min/avg/max: 0.06, 2.86, 7.39\n",
      "Loss after epoch 2: 12454163.0 (cumulative loss so far: 29701247.0) -> epoch took 402.62 s - vector norms min/avg/max: 0.06, 3.43, 7.12\n",
      "Loss after epoch 3: 11677254.0 (cumulative loss so far: 41378501.0) -> epoch took 399.07 s - vector norms min/avg/max: 0.06, 3.77, 7.61\n",
      "Loss after epoch 4: 11385046.0 (cumulative loss so far: 52763547.0) -> epoch took 393.5 s - vector norms min/avg/max: 0.06, 4.02, 8.03\n",
      "Loss after epoch 5: 11186762.0 (cumulative loss so far: 63950309.0) -> epoch took 393.53 s - vector norms min/avg/max: 0.06, 4.21, 8.42\n",
      "Loss after epoch 6: 11401256.0 (cumulative loss so far: 75351565.0) -> epoch took 387.86 s - vector norms min/avg/max: 0.06, 4.37, 8.62\n",
      "Loss after epoch 7: 11039624.0 (cumulative loss so far: 86391189.0) -> epoch took 390.87 s - vector norms min/avg/max: 0.06, 4.51, 8.91\n",
      "Loss after epoch 8: 11187965.0 (cumulative loss so far: 97579154.0) -> epoch took 390.82 s - vector norms min/avg/max: 0.06, 4.63, 9.03\n",
      "Loss after epoch 9: 11092349.0 (cumulative loss so far: 108671503.0) -> epoch took 388.05 s - vector norms min/avg/max: 0.06, 4.74, 9.19\n",
      "Loss after epoch 10: 10826345.0 (cumulative loss so far: 119497848.0) -> epoch took 388.38 s - vector norms min/avg/max: 0.06, 4.83, 9.35\n",
      "Loss after epoch 11: 10839720.0 (cumulative loss so far: 130337568.0) -> epoch took 387.98 s - vector norms min/avg/max: 0.06, 4.92, 9.59\n",
      "Loss after epoch 12: 10805905.0 (cumulative loss so far: 141143473.0) -> epoch took 408.54 s - vector norms min/avg/max: 0.06, 5.0, 9.79\n",
      "Loss after epoch 13: 10893877.0 (cumulative loss so far: 152037350.0) -> epoch took 392.71 s - vector norms min/avg/max: 0.06, 5.07, 9.95\n",
      "Loss after epoch 14: 10937611.0 (cumulative loss so far: 162974961.0) -> epoch took 391.96 s - vector norms min/avg/max: 0.06, 5.14, 10.15\n",
      "Loss after epoch 15: 10884178.0 (cumulative loss so far: 173859139.0) -> epoch took 390.51 s - vector norms min/avg/max: 0.06, 5.2, 10.26\n",
      "Loss after epoch 16: 10986536.0 (cumulative loss so far: 184845675.0) -> epoch took 408.11 s - vector norms min/avg/max: 0.06, 5.25, 10.39\n",
      "Loss after epoch 17: 10853041.0 (cumulative loss so far: 195698716.0) -> epoch took 401.1 s - vector norms min/avg/max: 0.06, 5.31, 10.44\n",
      "Loss after epoch 18: 10718404.0 (cumulative loss so far: 206417120.0) -> epoch took 390.2 s - vector norms min/avg/max: 0.06, 5.36, 10.57\n",
      "Loss after epoch 19: 10849410.0 (cumulative loss so far: 217266530.0) -> epoch took 388.1 s - vector norms min/avg/max: 0.06, 5.41, 10.66\n",
      "Loss after epoch 20: 10890958.0 (cumulative loss so far: 228157488.0) -> epoch took 391.79 s - vector norms min/avg/max: 0.06, 5.45, 10.69\n",
      "Loss after epoch 21: 10893525.0 (cumulative loss so far: 239051013.0) -> epoch took 388.26 s - vector norms min/avg/max: 0.06, 5.49, 10.73\n",
      "Loss after epoch 22: 10754276.0 (cumulative loss so far: 249805289.0) -> epoch took 394.18 s - vector norms min/avg/max: 0.06, 5.53, 10.86\n",
      "Loss after epoch 23: 10737873.0 (cumulative loss so far: 260543162.0) -> epoch took 395.42 s - vector norms min/avg/max: 0.06, 5.57, 10.92\n",
      "Loss after epoch 24: 10838086.0 (cumulative loss so far: 271381248.0) -> epoch took 396.9 s - vector norms min/avg/max: 0.06, 5.6, 11.11\n",
      "Loss after epoch 25: 10877369.0 (cumulative loss so far: 282258617.0) -> epoch took 401.96 s - vector norms min/avg/max: 0.06, 5.64, 11.22\n",
      "Loss after epoch 26: 10753752.0 (cumulative loss so far: 293012369.0) -> epoch took 396.93 s - vector norms min/avg/max: 0.06, 5.67, 11.23\n",
      "Loss after epoch 27: 10630557.0 (cumulative loss so far: 303642926.0) -> epoch took 397.93 s - vector norms min/avg/max: 0.06, 5.7, 11.33\n",
      "Loss after epoch 28: 10926436.0 (cumulative loss so far: 314569362.0) -> epoch took 393.55 s - vector norms min/avg/max: 0.06, 5.73, 11.35\n",
      "Loss after epoch 29: 10728925.0 (cumulative loss so far: 325298287.0) -> epoch took 391.66 s - vector norms min/avg/max: 0.06, 5.76, 11.4\n",
      "Loss after epoch 30: 10764450.0 (cumulative loss so far: 336062737.0) -> epoch took 384.82 s - vector norms min/avg/max: 0.06, 5.79, 11.43\n",
      "Loss after epoch 31: 10714116.0 (cumulative loss so far: 346776853.0) -> epoch took 383.27 s - vector norms min/avg/max: 0.06, 5.81, 11.44\n",
      "Loss after epoch 32: 10736152.0 (cumulative loss so far: 357513005.0) -> epoch took 388.61 s - vector norms min/avg/max: 0.06, 5.84, 11.49\n",
      "Loss after epoch 33: 10782667.0 (cumulative loss so far: 368295672.0) -> epoch took 390.79 s - vector norms min/avg/max: 0.06, 5.86, 11.51\n",
      "Loss after epoch 34: 10767461.0 (cumulative loss so far: 379063133.0) -> epoch took 391.78 s - vector norms min/avg/max: 0.06, 5.88, 11.58\n",
      "Loss after epoch 35: 10592395.0 (cumulative loss so far: 389655528.0) -> epoch took 395.68 s - vector norms min/avg/max: 0.06, 5.91, 11.63\n",
      "Loss after epoch 36: 10768515.0 (cumulative loss so far: 400424043.0) -> epoch took 391.69 s - vector norms min/avg/max: 0.06, 5.93, 11.72\n",
      "Loss after epoch 37: 10619484.0 (cumulative loss so far: 411043527.0) -> epoch took 386.34 s - vector norms min/avg/max: 0.06, 5.95, 11.78\n",
      "Loss after epoch 38: 10798862.0 (cumulative loss so far: 421842389.0) -> epoch took 393.23 s - vector norms min/avg/max: 0.06, 5.97, 11.81\n",
      "Loss after epoch 39: 10769209.0 (cumulative loss so far: 432611598.0) -> epoch took 391.92 s - vector norms min/avg/max: 0.06, 5.99, 11.9\n",
      "Loss after epoch 40: 10666770.0 (cumulative loss so far: 443278368.0) -> epoch took 386.75 s - vector norms min/avg/max: 0.06, 6.01, 11.96\n",
      "Loss after epoch 41: 10676225.0 (cumulative loss so far: 453954593.0) -> epoch took 385.58 s - vector norms min/avg/max: 0.06, 6.02, 11.97\n",
      "Loss after epoch 42: 10639557.0 (cumulative loss so far: 464594150.0) -> epoch took 393.29 s - vector norms min/avg/max: 0.06, 6.04, 12.04\n",
      "Loss after epoch 43: 10620229.0 (cumulative loss so far: 475214379.0) -> epoch took 390.93 s - vector norms min/avg/max: 0.06, 6.06, 12.03\n",
      "Loss after epoch 44: 10665292.0 (cumulative loss so far: 485879671.0) -> epoch took 393.51 s - vector norms min/avg/max: 0.06, 6.08, 12.09\n",
      "Loss after epoch 45: 10677954.0 (cumulative loss so far: 496557625.0) -> epoch took 391.23 s - vector norms min/avg/max: 0.06, 6.09, 12.17\n",
      "Loss after epoch 46: 10661015.0 (cumulative loss so far: 507218640.0) -> epoch took 394.12 s - vector norms min/avg/max: 0.06, 6.11, 12.25\n",
      "Loss after epoch 47: 10726910.0 (cumulative loss so far: 517945550.0) -> epoch took 392.59 s - vector norms min/avg/max: 0.06, 6.12, 12.31\n",
      "Loss after epoch 48: 10768894.0 (cumulative loss so far: 528714444.0) -> epoch took 392.61 s - vector norms min/avg/max: 0.06, 6.14, 12.32\n",
      "Loss after epoch 49: 10637771.0 (cumulative loss so far: 539352215.0) -> epoch took 394.45 s - vector norms min/avg/max: 0.06, 6.15, 12.32\n",
      "Loss after epoch 50: 10601114.0 (cumulative loss so far: 549953329.0) -> epoch took 392.3 s - vector norms min/avg/max: 0.06, 6.16, 12.34\n",
      "Loss after epoch 51: 10557896.0 (cumulative loss so far: 560511225.0) -> epoch took 393.76 s - vector norms min/avg/max: 0.06, 6.18, 12.36\n",
      "Loss after epoch 52: 10485404.0 (cumulative loss so far: 570996629.0) -> epoch took 399.27 s - vector norms min/avg/max: 0.06, 6.19, 12.41\n",
      "Loss after epoch 53: 10716419.0 (cumulative loss so far: 581713048.0) -> epoch took 393.12 s - vector norms min/avg/max: 0.06, 6.2, 12.44\n",
      "Loss after epoch 54: 10634272.0 (cumulative loss so far: 592347320.0) -> epoch took 394.6 s - vector norms min/avg/max: 0.06, 6.22, 12.45\n",
      "Loss after epoch 55: 10652295.0 (cumulative loss so far: 602999615.0) -> epoch took 387.6 s - vector norms min/avg/max: 0.06, 6.23, 12.49\n",
      "Loss after epoch 56: 10733219.0 (cumulative loss so far: 613732834.0) -> epoch took 387.94 s - vector norms min/avg/max: 0.06, 6.24, 12.51\n",
      "Loss after epoch 57: 10724077.0 (cumulative loss so far: 624456911.0) -> epoch took 388.76 s - vector norms min/avg/max: 0.06, 6.25, 12.53\n",
      "Loss after epoch 58: 10633527.0 (cumulative loss so far: 635090438.0) -> epoch took 388.67 s - vector norms min/avg/max: 0.06, 6.26, 12.55\n",
      "Loss after epoch 59: 10613516.0 (cumulative loss so far: 645703954.0) -> epoch took 393.9 s - vector norms min/avg/max: 0.06, 6.27, 12.55\n",
      "Loss after epoch 60: 10508171.0 (cumulative loss so far: 656212125.0) -> epoch took 403.41 s - vector norms min/avg/max: 0.06, 6.28, 12.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 61: 10765931.0 (cumulative loss so far: 666978056.0) -> epoch took 397.37 s - vector norms min/avg/max: 0.06, 6.29, 12.63\n",
      "Loss after epoch 62: 10648389.0 (cumulative loss so far: 677626445.0) -> epoch took 392.82 s - vector norms min/avg/max: 0.06, 6.3, 12.64\n",
      "Loss after epoch 63: 10737173.0 (cumulative loss so far: 688363618.0) -> epoch took 388.7 s - vector norms min/avg/max: 0.06, 6.31, 12.69\n",
      "Loss after epoch 64: 10470603.0 (cumulative loss so far: 698834221.0) -> epoch took 388.98 s - vector norms min/avg/max: 0.06, 6.32, 12.7\n",
      "Loss after epoch 65: 10499223.0 (cumulative loss so far: 709333444.0) -> epoch took 391.41 s - vector norms min/avg/max: 0.06, 6.33, 12.74\n",
      "Loss after epoch 66: 10685030.0 (cumulative loss so far: 720018474.0) -> epoch took 390.73 s - vector norms min/avg/max: 0.06, 6.34, 12.78\n",
      "Loss after epoch 67: 10652273.0 (cumulative loss so far: 730670747.0) -> epoch took 387.79 s - vector norms min/avg/max: 0.06, 6.35, 12.81\n",
      "Loss after epoch 68: 10532841.0 (cumulative loss so far: 741203588.0) -> epoch took 388.03 s - vector norms min/avg/max: 0.06, 6.36, 12.84\n",
      "Loss after epoch 69: 10675698.0 (cumulative loss so far: 751879286.0) -> epoch took 390.49 s - vector norms min/avg/max: 0.06, 6.36, 12.86\n",
      "Loss after epoch 70: 10624414.0 (cumulative loss so far: 762503700.0) -> epoch took 387.56 s - vector norms min/avg/max: 0.06, 6.37, 12.89\n",
      "Loss after epoch 71: 10616068.0 (cumulative loss so far: 773119768.0) -> epoch took 387.17 s - vector norms min/avg/max: 0.06, 6.38, 12.92\n",
      "Loss after epoch 72: 10569627.0 (cumulative loss so far: 783689395.0) -> epoch took 387.16 s - vector norms min/avg/max: 0.06, 6.39, 12.96\n",
      "Loss after epoch 73: 10469409.0 (cumulative loss so far: 794158804.0) -> epoch took 385.55 s - vector norms min/avg/max: 0.06, 6.39, 12.98\n",
      "Loss after epoch 74: 10391913.0 (cumulative loss so far: 804550717.0) -> epoch took 391.73 s - vector norms min/avg/max: 0.06, 6.4, 12.98\n",
      "Loss after epoch 75: 10460562.0 (cumulative loss so far: 815011279.0) -> epoch took 387.51 s - vector norms min/avg/max: 0.06, 6.41, 13.02\n",
      "Loss after epoch 76: 10606798.0 (cumulative loss so far: 825618077.0) -> epoch took 390.23 s - vector norms min/avg/max: 0.06, 6.41, 13.03\n",
      "Loss after epoch 77: 10644096.0 (cumulative loss so far: 836262173.0) -> epoch took 388.46 s - vector norms min/avg/max: 0.06, 6.42, 13.05\n",
      "Loss after epoch 78: 10363992.0 (cumulative loss so far: 846626165.0) -> epoch took 395.71 s - vector norms min/avg/max: 0.06, 6.42, 13.05\n",
      "Loss after epoch 79: 10581668.0 (cumulative loss so far: 857207833.0) -> epoch took 393.77 s - vector norms min/avg/max: 0.06, 6.43, 13.07\n",
      "Loss after epoch 80: 10578357.0 (cumulative loss so far: 867786190.0) -> epoch took 392.33 s - vector norms min/avg/max: 0.06, 6.43, 13.09\n",
      "Loss after epoch 81: 10465792.0 (cumulative loss so far: 878251982.0) -> epoch took 388.1 s - vector norms min/avg/max: 0.06, 6.44, 13.11\n",
      "Loss after epoch 82: 10644358.0 (cumulative loss so far: 888896340.0) -> epoch took 384.02 s - vector norms min/avg/max: 0.06, 6.44, 13.11\n",
      "Loss after epoch 83: 10464632.0 (cumulative loss so far: 899360972.0) -> epoch took 383.28 s - vector norms min/avg/max: 0.06, 6.45, 13.13\n",
      "Loss after epoch 84: 10476551.0 (cumulative loss so far: 909837523.0) -> epoch took 387.67 s - vector norms min/avg/max: 0.06, 6.45, 13.14\n",
      "Loss after epoch 85: 10549586.0 (cumulative loss so far: 920387109.0) -> epoch took 386.67 s - vector norms min/avg/max: 0.06, 6.46, 13.16\n",
      "Loss after epoch 86: 10507150.0 (cumulative loss so far: 930894259.0) -> epoch took 383.87 s - vector norms min/avg/max: 0.06, 6.46, 13.19\n",
      "Loss after epoch 87: 10614424.0 (cumulative loss so far: 941508683.0) -> epoch took 385.56 s - vector norms min/avg/max: 0.06, 6.46, 13.2\n",
      "Loss after epoch 88: 10564416.0 (cumulative loss so far: 952073099.0) -> epoch took 387.4 s - vector norms min/avg/max: 0.06, 6.47, 13.21\n",
      "Loss after epoch 89: 10616934.0 (cumulative loss so far: 962690033.0) -> epoch took 389.78 s - vector norms min/avg/max: 0.06, 6.47, 13.23\n",
      "Loss after epoch 90: 10431299.0 (cumulative loss so far: 973121332.0) -> epoch took 390.81 s - vector norms min/avg/max: 0.06, 6.47, 13.23\n",
      "Loss after epoch 91: 10531177.0 (cumulative loss so far: 983652509.0) -> epoch took 388.8 s - vector norms min/avg/max: 0.06, 6.48, 13.24\n",
      "Loss after epoch 92: 10464689.0 (cumulative loss so far: 994117198.0) -> epoch took 386.65 s - vector norms min/avg/max: 0.06, 6.48, 13.25\n",
      "Loss after epoch 93: 10452605.0 (cumulative loss so far: 1004569803.0) -> epoch took 387.18 s - vector norms min/avg/max: 0.06, 6.48, 13.25\n",
      "Loss after epoch 94: 10288620.0 (cumulative loss so far: 1014858423.0) -> epoch took 387.28 s - vector norms min/avg/max: 0.06, 6.48, 13.26\n",
      "Loss after epoch 95: 10415668.0 (cumulative loss so far: 1025274091.0) -> epoch took 385.93 s - vector norms min/avg/max: 0.06, 6.48, 13.26\n",
      "Loss after epoch 96: 10371373.0 (cumulative loss so far: 1035645464.0) -> epoch took 387.73 s - vector norms min/avg/max: 0.06, 6.49, 13.27\n",
      "Loss after epoch 97: 10539054.0 (cumulative loss so far: 1046184518.0) -> epoch took 397.27 s - vector norms min/avg/max: 0.06, 6.49, 13.27\n",
      "Loss after epoch 98: 10570302.0 (cumulative loss so far: 1056754820.0) -> epoch took 393.12 s - vector norms min/avg/max: 0.06, 6.49, 13.27\n",
      "Loss after epoch 99: 10413221.0 (cumulative loss so far: 1067168041.0) -> epoch took 403.72 s - vector norms min/avg/max: 0.06, 6.49, 13.27\n",
      "Loss after epoch 100: 10484793.0 (cumulative loss so far: 1077652834.0) -> epoch took 396.54 s - vector norms min/avg/max: 0.06, 6.49, 13.28\n",
      "Word2Vec embeddings have shape (1855603, 64)\n",
      "CPU times: user 10d 15h 9min, sys: 4h 50min 3s, total: 10d 19h 59min 4s\n",
      "Wall time: 10h 56min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "w2vec = Word2Vec(\n",
    "    sentences=sentences,\n",
    "    epochs=100,\n",
    "    vector_size= 64,\n",
    "    alpha=0.05,\n",
    "    min_alpha=0.001,\n",
    "    window = 5, \n",
    "    negative = 12,\n",
    "    ns_exponent = 0.1, \n",
    "    sg = 1, \n",
    "    min_count=1, \n",
    "    workers=48,\n",
    "    compute_loss=True, \n",
    "    callbacks=[callback()],\n",
    ")\n",
    "\n",
    "index_to_aid = w2vec.wv.index_to_key\n",
    "aid_to_index_dict = {aid:index for index,aid in enumerate(index_to_aid)}\n",
    "aid_to_index = [aid_to_index_dict[i] for i in range(len(aid_to_index_dict))]\n",
    "embs = w2vec.wv.vectors[aid_to_index]\n",
    "print('Word2Vec embeddings have shape',embs.shape)\n",
    "with open('matrices/w2v_100.npy', 'wb') as f:\n",
    "    np.save(f, embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cdb460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0895a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
